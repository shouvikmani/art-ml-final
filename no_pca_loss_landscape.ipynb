{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No PCA Loss Landscapes\n",
    "\n",
    "An approach for computing and visualizing 3D loss landscapes for high-dimensional models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LogisticRegression():\n",
    "    \n",
    "    def loss(self, X, y, theta):\n",
    "        YX = X * y[:,None]\n",
    "        hy = YX @ theta\n",
    "        loss = np.log(1+np.exp(-hy)).mean()\n",
    "        error = (hy <= 0).mean()\n",
    "        return loss, error\n",
    "    \n",
    "    def gradient(self, X, y, theta):\n",
    "        YX = X * y[:,None]\n",
    "        m = X.shape[0]\n",
    "        gradient = -YX.T @ (1/(1+np.exp(YX @ theta)))/m\n",
    "        return gradient\n",
    "\n",
    "    def gradient_descent(self, X, y, alpha, iters):\n",
    "        m,n = X.shape\n",
    "        theta = np.zeros((iters+1, n))\n",
    "        loss, err = np.zeros(iters), np.zeros(iters)\n",
    "        for t in range(iters):\n",
    "            loss[t], err[t] = self.loss(X, y, theta[t])\n",
    "            theta[t+1] -= alpha * self.gradient(X, y, theta[t])\n",
    "        theta = theta[0:iters, :]\n",
    "        return theta, loss, err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SVM():\n",
    "  \n",
    "    def loss(self, X, y, theta):\n",
    "        YX = X * y[:,None]\n",
    "        hy = YX @ theta\n",
    "        loss = np.maximum(1-hy,0).mean()\n",
    "        error = (hy <= 0).mean()\n",
    "        return loss, error\n",
    "    \n",
    "    def gradient(self, X, y, theta):\n",
    "        YX = X * y[:,None]\n",
    "        m = X.shape[0]\n",
    "        gradient = -YX.T @ (YX @ theta <= 1)/m\n",
    "        return gradient\n",
    "\n",
    "    def gradient_descent(self, X, y, alpha, iters):\n",
    "        m,n = X.shape\n",
    "        theta = np.zeros((iters+1, n))\n",
    "        loss, err = np.zeros(iters), np.zeros(iters)\n",
    "        for t in range(iters):\n",
    "            loss[t], err[t] = self.loss(X, y, theta[t])\n",
    "            theta[t+1] -= alpha * self.gradient(X, y, theta[t])\n",
    "        theta = theta[0:iters, :]\n",
    "        return theta, loss, err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nn(x, W, b, f):\n",
    "    \"\"\"\n",
    "    Compute output of a neural network.\n",
    "\n",
    "    Input:\n",
    "        x: numpy array of input\n",
    "        W: list of numpy arrays for W parameters\n",
    "        b: list of numpy arraos for b parameters\n",
    "        f: list of activation functions for each layer\n",
    "\n",
    "    Output:\n",
    "        z: list of activationsn, where each element in the list is a tuple:\n",
    "           (z_i, z'_i)\n",
    "           for z_i and z'_i each being a numpy array of activations/derivatives\n",
    "    \"\"\"\n",
    "\n",
    "    z = [(x,)] + [[]]*len(W)\n",
    "    for i in range(len(W)):\n",
    "        z[i+1] = (f[i](W[i] @ z[i][0] + b[i])[0],\n",
    "                  f[i](W[i] @ z[i][0] + b[i])[1])\n",
    "    return z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nn_loss(x, y, W, b, f):\n",
    "    \"\"\"\n",
    "    Compute loss of a neural net prediction, plus gradients of parameters\n",
    "\n",
    "    Input:\n",
    "        x: numpy array of input\n",
    "        y: numpy array of output\n",
    "        W: list of numpy arrays for W parameters\n",
    "        b: list of numpy arrays for b parameters\n",
    "        f: list of activation functions for each layer\n",
    "\n",
    "    Output tuple: (L, dW, db)\n",
    "        L: softmax loss on this example\n",
    "        dW: list of numpy arrays for gradients of W parameters\n",
    "        db: list of numpy arrays for gradients of b parameters\n",
    "    \"\"\"\n",
    "\n",
    "    z = nn(x,W,b,f)\n",
    "    L, dL = softmax_loss(z[-1][0], y)\n",
    "    \n",
    "    db = [np.zeros(bi.shape) for bi in b]\n",
    "    dW = [np.zeros(Wi.shape) for Wi in W]\n",
    "    \n",
    "    g = dL\n",
    "    db[-1] = g * z[-1][1]\n",
    "    dW[-1] = (g * z[-1][1])[:,None] @ z[-2][0][None,:]\n",
    "    \n",
    "    for i in range(len(db)-2, -1, -1):\n",
    "        g = W[i+1].T @ (g * z[i+2][1])\n",
    "        db[i] = g * z[i+1][1]\n",
    "        dW[i] = (g * z[i+1][1])[:,None] @ z[i][0][None,:]\n",
    "\n",
    "    return L, dW, db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nn_sgd(X,y, Xt, yt, W, b, f, epochs=10, alpha = 0.01):\n",
    "    \"\"\"\n",
    "    Run stochastic gradient descent to solve linear softmax regression.\n",
    "\n",
    "    Inputs:\n",
    "        X: numpy array of training inputs\n",
    "        y: numpy array of training outputs\n",
    "        Xt: numpy array of testing inputs\n",
    "        yt: numpy array of testing outputs\n",
    "        W: list of W parameters (with initial values)\n",
    "        b: list of b parameters (with initial values)\n",
    "        f: list of activation functions\n",
    "        epochs: number of passes to make over the whole training set\n",
    "        alpha: step size\n",
    "\n",
    "    Output: None (you can directly update the W and b inputs in place)\n",
    "    \"\"\"\n",
    "    m = X.shape[0]\n",
    "    print(\"{0:10}|{1:10}|{2:10}|{3:10}\".\\\n",
    "          format(\"Test Err\", \"Train Err\", \"Test Loss\", \"Train Loss\"))\n",
    "\n",
    "    # TODO: Modify W and b in-place.\n",
    "    for i in range(epochs):\n",
    "        yp = np.vstack([nn(x, W, b, f)[-1][0] for x in X_train])\n",
    "        ypt = np.vstack([nn(x, W, b, f)[-1][0] for x in X_test])\n",
    "        print_errors(yp, y, ypt, yt)\n",
    "        for i in range(m):\n",
    "            x_i = X_train[i]\n",
    "            y_i = y_train[i]\n",
    "            L, dW, db = nn_loss(x_i, y_i, W, b, f)\n",
    "            for j in range(len(W)):\n",
    "                b[j] -= alpha * db[j]\n",
    "                W[j] -= alpha * dW[j]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "layer_sizes = [784, 200, 100, 10]\n",
    "W = [0.1*np.random.randn(n,m) for m,n in zip(layer_sizes[:-1], layer_sizes[1:])]\n",
    "b = [0.1*np.random.randn(n) for n in layer_sizes[1:]]\n",
    "f = [f_relu]*(len(layer_sizes)-2) + [f_lin]\n",
    "\n",
    "z = nn(X_train[0], W, b, f)\n",
    "\n",
    "L, dW, db = nn_loss(X_train[0], y_train[0], W, b, f)\n",
    "\n",
    "# # nn_sgd should update W and b in-place.\n",
    "nn_sgd(X_train, y_train, X_test, y_test, W, b, f, epochs=10, alpha=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset: Iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions: (100, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length</th>\n",
       "      <th>sepal width</th>\n",
       "      <th>petal length</th>\n",
       "      <th>petal width</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length  sepal width  petal length  petal width        label\n",
       "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
       "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
       "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
       "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
       "4           5.0          3.6           1.4          0.2  Iris-setosa"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_table('data/iris.data.txt', sep=',', \n",
    "                   names=['sepal length', 'sepal width', 'petal length', 'petal width', 'label'])\n",
    "df = df[df['label'].isin(['Iris-setosa', 'Iris-versicolor'])]   # only keep 2 classes\n",
    "df = df.reset_index(drop=True)\n",
    "print('Dimensions:', df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train a logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df.iloc[:,0:4].as_matrix()\n",
    "y = ((df['label'] == 'Iris-setosa') * 2 - 1).as_matrix()   # convert to 1 / -1 labels\n",
    "lr_model = LogisticRegression()\n",
    "theta, loss, err = lr_model.gradient_descent(X, y, 0.1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.09191999, -0.02300177, -0.10521241, -0.03668105])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(theta.shape)\n",
    "theta = theta[-1]   # chose best theta\n",
    "theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize loss landscape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize loss surface by holding all but one parameter constant at their optimal values. Sweep out values of the non-constant parameter around it's optimal value. Evaluate the loss for each combination of parameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABHgAAAEYCAYAAAAnPkG+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10cce5eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16, 4))\n",
    "for i in range(len(theta)):\n",
    "    theta_to_change = theta[i]   # the parameter value not held constant\n",
    "    theta_to_change_sweep = np.linspace(start=(theta_to_change - 1), stop=(theta_to_change + 1), num=100)\n",
    "    all_theta_values = np.vstack([theta for i in range(100)])   # stack theta values\n",
    "    all_theta_values[:,i] = theta_to_change_sweep   # insert in non-constant theta values\n",
    "    loss = [lr_model.loss(X, y, theta_)[0] for theta_ in all_theta_values]\n",
    "    plt.subplot(1, 4, i+1)\n",
    "    plt.ylim([0,3])\n",
    "    plt.plot(theta_to_change_sweep, loss)\n",
    "    plt.title('Loss for Changing Parameter {}'.format(i))\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Paramter {}'.format(i))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize loss surface by holding all but two parameters constant at their optimal values. Sweep out values of the non-constant parameters around their optimal values. Evaluate the loss for each combination of parameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Projecting the theta parameters down to 2 dimensions through PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = (theta - theta.mean(axis=0)) / theta.std(axis=0)   # normalizing theta before PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "theta_reduced = pca.fit_transform(theta)\n",
    "theta_reduced = pd.DataFrame(theta_reduced, columns=['theta_0', 'theta_1'])\n",
    "\n",
    "theta_reduced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(theta_reduced[\"theta_0\"], theta_reduced[\"theta_1\"], lw=0.5)\n",
    "plt.title(\"Gradient descent trajectory: PCA dimensions\", fontsize=14)\n",
    "plt.xlabel(\"PC theta 0\", fontsize=13)\n",
    "plt.ylabel(\"PC theta 1\", fontsize=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a dense grid of points centered around the thetas from each iteration of gradient descent. These sampled points will be used for evaluating loss in their regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(theta_reduced[\"theta_0\"], theta_reduced[\"theta_1\"], lw=0.5)\n",
    "\n",
    "num_samples = 40\n",
    "offset = 1\n",
    "min_theta_0, min_theta_1 = theta_reduced[\"theta_0\"].min(), theta_reduced[\"theta_1\"].min()\n",
    "max_theta_0, max_theta_1 = theta_reduced[\"theta_0\"].max(), theta_reduced[\"theta_1\"].max()\n",
    "theta_0_range = np.linspace(min_theta_0 - offset, max_theta_0 + offset, num_samples)\n",
    "theta_1_range = np.linspace(min_theta_1 - offset, max_theta_1 + offset, num_samples)\n",
    "theta_0_points, theta_1_points = np.meshgrid(theta_0_range, theta_1_range)\n",
    "plt.plot(theta_0_points, theta_1_points, '.', ms=1, color='k')\n",
    "plt.title(\"Theta point grid for PCA dimensions\", fontsize=14)\n",
    "plt.xlabel(\"PC theta 0\", fontsize=13)\n",
    "plt.ylabel(\"PC theta 1\", fontsize=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a matrix of the 2D grid of points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_theta_points_2D = []\n",
    "for theta_0 in theta_0_range:\n",
    "    for theta_1 in theta_1_range:\n",
    "        all_theta_points_2D.append([theta_0, theta_1])\n",
    "all_theta_points_2D = np.array(all_theta_points_2D)\n",
    "print(all_theta_points_2D.shape)\n",
    "print(all_theta_points_2D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project theta parameters from the 2D points back into their original space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_theta_points_projected = pca.inverse_transform(all_theta_points_2D)\n",
    "print(all_theta_points_projected.shape)\n",
    "print(all_theta_points_projected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute loss from projected theta values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_rows, grid_cols = theta_0_points.shape\n",
    "loss = np.zeros((grid_rows, grid_cols))\n",
    "for i in range(grid_rows):\n",
    "    for j in range(grid_cols):\n",
    "        theta_ij = all_theta_points_projected[i*grid_rows + j]\n",
    "        loss[i, j] = lr_model.loss(X, y, theta_ij)[0]\n",
    "print(loss.shape)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing the loss landscape with a 3D plot.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits import mplot3d\n",
    "fig = plt.figure(figsize=(10,6))\n",
    "ax = plt.axes(projection='3d')\n",
    "\n",
    "ax.plot_surface(theta_0_points, theta_1_points, loss, cmap='viridis')\n",
    "ax.set_title('PCA loss landscape: logistic regression on Iris data',\n",
    "             fontsize=14)\n",
    "ax.set_xlabel('PC theta 0', fontsize=13)\n",
    "ax.set_ylabel('PC theta 1', fontsize=13)\n",
    "ax.set_zlabel('Loss \\n(projected thetas)')\n",
    "ax.view_init(40, 220)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving theta and loss point values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'theta_0': theta_0_points.reshape(num_samples**2),\n",
    "                   'theta_1': theta_1_points.reshape(num_samples**2),\n",
    "                   'loss': loss.reshape(num_samples**2)},\n",
    "                  columns = ['theta_0', 'theta_1', 'loss'])\n",
    "df.to_csv('data/PCA_loss_LR_iris.csv', index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train an SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svm_model = SVM()\n",
    "theta, loss, err = svm_model.gradient_descent(X, y, 0.1, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Projecting the theta parameters down to 2 dimensions through PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "theta = (theta - theta.mean(axis=0)) / theta.std(axis=0)   # normalizing theta before PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "theta_reduced = pca.fit_transform(theta)\n",
    "theta_reduced = pd.DataFrame(theta_reduced, columns=['theta_0', 'theta_1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a dense grid of points centered around the thetas from each iteration of gradient descent. These sampled points will be used for evaluating loss in their regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(theta_reduced[\"theta_0\"], theta_reduced[\"theta_1\"], lw=0.5)\n",
    "\n",
    "num_samples = 40\n",
    "offset = 1\n",
    "min_theta_0, min_theta_1 = theta_reduced[\"theta_0\"].min(), theta_reduced[\"theta_1\"].min()\n",
    "max_theta_0, max_theta_1 = theta_reduced[\"theta_0\"].max(), theta_reduced[\"theta_1\"].max()\n",
    "theta_0_range = np.linspace(min_theta_0 - offset, max_theta_0 + offset, num_samples)\n",
    "theta_1_range = np.linspace(min_theta_1 - offset, max_theta_1 + offset, num_samples)\n",
    "theta_0_points, theta_1_points = np.meshgrid(theta_0_range, theta_1_range)\n",
    "plt.plot(theta_0_points, theta_1_points, '.', ms=1, color='k')\n",
    "plt.title(\"Theta point grid for PCA dimensions\", fontsize=14)\n",
    "plt.xlabel(\"PC theta 0\", fontsize=13)\n",
    "plt.ylabel(\"PC theta 1\", fontsize=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a matrix of the 2D grid of points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_theta_points_2D = []\n",
    "for theta_0 in theta_0_range:\n",
    "    for theta_1 in theta_1_range:\n",
    "        all_theta_points_2D.append([theta_0, theta_1])\n",
    "all_theta_points_2D = np.array(all_theta_points_2D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project theta parameters from the 2D points back into their original space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_theta_points_projected = pca.inverse_transform(all_theta_points_2D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute loss from projected theta values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid_rows, grid_cols = theta_0_points.shape\n",
    "loss = np.zeros((grid_rows, grid_cols))\n",
    "for i in range(grid_rows):\n",
    "    for j in range(grid_cols):\n",
    "        theta_ij = all_theta_points_projected[i*grid_rows + j]\n",
    "        loss[i, j] = svm_model.loss(X, y, theta_ij)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing the loss landscape with a 3D plot.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits import mplot3d\n",
    "fig = plt.figure(figsize=(10,6))\n",
    "ax = plt.axes(projection='3d')\n",
    "\n",
    "ax.plot_surface(theta_0_points, theta_1_points, loss, cmap='viridis')\n",
    "ax.set_title('PCA loss landscape: SVM on Iris data',\n",
    "             fontsize=14)\n",
    "ax.set_xlabel('PC theta 0', fontsize=13)\n",
    "ax.set_ylabel('PC theta 1', fontsize=13)\n",
    "ax.set_zlabel('Loss \\n(projected thetas)')\n",
    "ax.view_init(30, 140)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving theta and loss point values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'theta_0': theta_0_points.reshape(num_samples**2),\n",
    "                   'theta_1': theta_1_points.reshape(num_samples**2),\n",
    "                   'loss': loss.reshape(num_samples**2)},\n",
    "                  columns = ['theta_0', 'theta_1', 'loss'])\n",
    "df.to_csv('data/PCA_loss_SVM_iris.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset: Breast Cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/breast-cancer.csv\")\n",
    "df = df.drop(['id', 'Unnamed: 32'], axis=1)\n",
    "print('Dimensions:', df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train a logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df.iloc[:,1:31].as_matrix()\n",
    "X = (X - X.mean(axis=0))/X.std(axis=0)\n",
    "y = ((df['diagnosis'] == 'M') * 2 - 1).as_matrix()   # convert to 1 / -1 labels\n",
    "lr_model = LogisticRegression()\n",
    "theta, loss, err = lr_model.gradient_descent(X, y, 0.1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(theta.shape)\n",
    "theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Projecting the theta parameters down to 2 dimensions through PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = (theta - theta.mean(axis=0)) / theta.std(axis=0)   # normalizing theta before PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "theta_reduced = pca.fit_transform(theta)\n",
    "theta_reduced = pd.DataFrame(theta_reduced, columns=['theta_0', 'theta_1'])\n",
    "\n",
    "theta_reduced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(theta_reduced[\"theta_0\"], theta_reduced[\"theta_1\"], lw=0.5)\n",
    "plt.title(\"Gradient descent trajectory: PCA dimensions\", fontsize=14)\n",
    "plt.xlabel(\"PC theta 0\", fontsize=13)\n",
    "plt.ylabel(\"PC theta 1\", fontsize=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a dense grid of points centered around the thetas from each iteration of gradient descent. These sampled points will be used for evaluating loss in their regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(theta_reduced[\"theta_0\"], theta_reduced[\"theta_1\"], lw=0.5)\n",
    "\n",
    "num_samples = 40\n",
    "offset = 1\n",
    "min_theta_0, min_theta_1 = theta_reduced[\"theta_0\"].min(), theta_reduced[\"theta_1\"].min()\n",
    "max_theta_0, max_theta_1 = theta_reduced[\"theta_0\"].max(), theta_reduced[\"theta_1\"].max()\n",
    "theta_0_range = np.linspace(min_theta_0 - offset, max_theta_0 + offset, num_samples)\n",
    "theta_1_range = np.linspace(min_theta_1 - offset, max_theta_1 + offset, num_samples)\n",
    "theta_0_points, theta_1_points = np.meshgrid(theta_0_range, theta_1_range)\n",
    "plt.plot(theta_0_points, theta_1_points, '.', ms=1, color='k')\n",
    "plt.title(\"Theta point grid for PCA dimensions\", fontsize=14)\n",
    "plt.xlabel(\"PC theta 0\", fontsize=13)\n",
    "plt.ylabel(\"PC theta 1\", fontsize=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a matrix of the 2D grid of points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_theta_points_2D = []\n",
    "for theta_0 in theta_0_range:\n",
    "    for theta_1 in theta_1_range:\n",
    "        all_theta_points_2D.append([theta_0, theta_1])\n",
    "all_theta_points_2D = np.array(all_theta_points_2D)\n",
    "print(all_theta_points_2D.shape)\n",
    "print(all_theta_points_2D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project theta parameters from the 2D points back into their original space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_theta_points_projected = pca.inverse_transform(all_theta_points_2D)\n",
    "print(all_theta_points_projected.shape)\n",
    "print(all_theta_points_projected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute loss from projected theta values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_rows, grid_cols = theta_0_points.shape\n",
    "loss = np.zeros((grid_rows, grid_cols))\n",
    "for i in range(grid_rows):\n",
    "    for j in range(grid_cols):\n",
    "        theta_ij = all_theta_points_projected[i*grid_rows + j]\n",
    "        loss[i, j] = lr_model.loss(X, y, theta_ij)[0]\n",
    "print(loss.shape)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing the loss landscape with a 3D plot.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits import mplot3d\n",
    "fig = plt.figure(figsize=(10,6))\n",
    "ax = plt.axes(projection='3d')\n",
    "\n",
    "ax.plot_surface(theta_0_points, theta_1_points, loss, cmap='viridis')\n",
    "ax.set_title('PCA loss landscape: \\nlogistic regression on breast cancer data',\n",
    "             fontsize=14)\n",
    "ax.set_xlabel('PC theta 0', fontsize=13)\n",
    "ax.set_ylabel('PC theta 1', fontsize=13)\n",
    "ax.set_zlabel('Loss \\n(projected thetas)')\n",
    "ax.view_init(20, 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving theta and loss point values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'theta_0': theta_0_points.reshape(num_samples**2),\n",
    "                   'theta_1': theta_1_points.reshape(num_samples**2),\n",
    "                   'loss': loss.reshape(num_samples**2)},\n",
    "                  columns = ['theta_0', 'theta_1', 'loss'])\n",
    "df.to_csv('data/PCA_loss_LR_cancer.csv', index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train an SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svm_model = SVM()\n",
    "theta, loss, err = svm_model.gradient_descent(X, y, 0.1, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Projecting the theta parameters down to 2 dimensions through PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "theta = (theta - theta.mean(axis=0)) / theta.std(axis=0)   # normalizing theta before PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "theta_reduced = pca.fit_transform(theta)\n",
    "theta_reduced = pd.DataFrame(theta_reduced, columns=['theta_0', 'theta_1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a dense grid of points centered around the thetas from each iteration of gradient descent. These sampled points will be used for evaluating loss in their regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(theta_reduced[\"theta_0\"], theta_reduced[\"theta_1\"], lw=0.5)\n",
    "\n",
    "num_samples = 40\n",
    "offset = 1\n",
    "min_theta_0, min_theta_1 = theta_reduced[\"theta_0\"].min(), theta_reduced[\"theta_1\"].min()\n",
    "max_theta_0, max_theta_1 = theta_reduced[\"theta_0\"].max(), theta_reduced[\"theta_1\"].max()\n",
    "theta_0_range = np.linspace(min_theta_0 - offset, max_theta_0 + offset, num_samples)\n",
    "theta_1_range = np.linspace(min_theta_1 - offset, max_theta_1 + offset, num_samples)\n",
    "theta_0_points, theta_1_points = np.meshgrid(theta_0_range, theta_1_range)\n",
    "plt.plot(theta_0_points, theta_1_points, '.', ms=1, color='k')\n",
    "plt.title(\"Theta point grid for PCA dimensions\", fontsize=14)\n",
    "plt.xlabel(\"PC theta 0\", fontsize=13)\n",
    "plt.ylabel(\"PC theta 1\", fontsize=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a matrix of the 2D grid of points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_theta_points_2D = []\n",
    "for theta_0 in theta_0_range:\n",
    "    for theta_1 in theta_1_range:\n",
    "        all_theta_points_2D.append([theta_0, theta_1])\n",
    "all_theta_points_2D = np.array(all_theta_points_2D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project theta parameters from the 2D points back into their original space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_theta_points_projected = pca.inverse_transform(all_theta_points_2D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute loss from projected theta values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid_rows, grid_cols = theta_0_points.shape\n",
    "loss = np.zeros((grid_rows, grid_cols))\n",
    "for i in range(grid_rows):\n",
    "    for j in range(grid_cols):\n",
    "        theta_ij = all_theta_points_projected[i*grid_rows + j]\n",
    "        loss[i, j] = svm_model.loss(X, y, theta_ij)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing the loss landscape with a 3D plot.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits import mplot3d\n",
    "fig = plt.figure(figsize=(10,6))\n",
    "ax = plt.axes(projection='3d')\n",
    "\n",
    "ax.plot_surface(theta_0_points, theta_1_points, loss, cmap='viridis')\n",
    "ax.set_title('PCA loss landscape: \\nSVM on breast cancer data',\n",
    "             fontsize=14)\n",
    "ax.set_xlabel('PC theta 0', fontsize=13)\n",
    "ax.set_ylabel('PC theta 1', fontsize=13)\n",
    "ax.set_zlabel('Loss \\n(projected thetas)')\n",
    "ax.view_init(30, 180)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving theta and loss point values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'theta_0': theta_0_points.reshape(num_samples**2),\n",
    "                   'theta_1': theta_1_points.reshape(num_samples**2),\n",
    "                   'loss': loss.reshape(num_samples**2)},\n",
    "                  columns = ['theta_0', 'theta_1', 'loss'])\n",
    "df.to_csv('data/PCA_loss_SVM_cancer.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py36]",
   "language": "python",
   "name": "Python [py36]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
